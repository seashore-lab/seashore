# Selective Attention

Selective attention means you donâ€™t include *everything* in context. You include:

- the most relevant memories
- the most relevant retrieved chunks
- the most relevant recent messages

This is usually implemented with:

- retrieval (vector + hybrid)
- score thresholds
- time windows
